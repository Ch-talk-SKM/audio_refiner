### ğŸ¯ Target-Speaker Extraction â€” ì•„í‚¤í…ì²˜Â·ì°¨ë³„ì ë§Œ ì •ë¦¬


| ëª¨ë¸                             | í•µì‹¬ êµ¬ì¡°(ìš”ì•½)                                                                                                                                                                                | ìŠ¤í”¼ì»¤ ë‹¨ì„œ íˆ¬ì… ë°©ì‹                                                                                                                 | ì£¼ìš” ì†ì‹¤â€†/â€†ì¶œë ¥                                                             | ëšœë ·í•œ ì°¨ë³„ì                                                                                                                 |
| ------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------- |
| **VoiceFilter** (maum-ai)      | STFT (256 FFT, 32 ms) â†’ **8 Conv2D(5Ã—5, 256) + BN + ReLU** â†’ **2 Ã— BLSTM(800)** â†’ FC 600 â†’ **sigmoid TF-mask** â†’ iSTFT                                                                   | 256-dim **d-vector**ë¥¼ ê° frame featureì— **ì±„ë„ concat** ([GitHub][1], [ar5iv][2])                                               | MSE ë˜ëŠ” power-law ì••ì¶• MSEë¡œ TF-mask í•™ìŠµâ€†; ì¶œë ¥ì€ ìœ„ìƒ ê³µìœ  TF-maskëœ waveform      | (i) CNN-BLSTM íŒŒì´í”„ë¼ì¸ = ê²½ëŸ‰Â·ì•ˆì • *(\~10 M)*<br> (ii) ìŠ¤í”¼ì»¤ ì¸ì½”ë” **ê³ ì •** â†’ ë¶„ë¦¬Â·ì¸ì½”ë” ì™„ì „ ë¶„ë¦¬ ì„¤ê³„                                       |
| **SpeakerBeam** (BUTSpeechFIT) | log-Mel â†’ **6 Ã— Bi-GRU(512)** + **ì‹œì ë³„ TF-mask MLP**                                                                                                                                      | ì„ë² ë”©(256\~512) â†’ **â€œAdaptation Layerâ€**(Linear+Sigmoid)ë¡œ **ì¤‘ê°„ hidden stateë¥¼ ê²Œì´íŒ…**. `--i_adapt_layer` ë¡œ ì‚½ì… ì§€ì  ì„ íƒ ([GitHub][3]) | TF-mask + Si-SNR; ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ëŠ” *Libri2Mix*                                 | (i) **ì ì‘ ê³„ì¸µ í•˜ë‚˜**ë¡œ ì „ì²´ ë„¤íŠ¸ì›Œí¬ë¥¼ speaker-awareí™”â€”ë§¤ìš° ë‹¨ìˆœÂ·ê°€ë³ë‹¤.<br>(ii) Asteroid API ê¸°ë°˜ â†’ Conv-TasNet Â· TFTNet ë“±ìœ¼ë¡œ ì‰½ê²Œ êµì²´          |
| **SpEx / SpEx+**               | **ê³µìœ  1-D Conv Encoder (stride 2) ë‹¤ì¤‘ dilation â†’ 512-chan latent**<br>â€¢ **Speaker Encoder**: LSTM 2Ã—256 + ResBlocks â†’ 256-vec<br>â€¢ **Separator**: LSTM Stack â†’ **Mask Ã— Latent** âœ Decoder | mixture latentê³¼ **ì°¸ì¡° latentë¥¼ *ì›ì  ì—°ì‚°*** (dot-prod) â†’ speaker íŠ¹í™” weight ì‚°ì¶œ í›„ **waveform ì§ì ‘ ì¬êµ¬ì„±** ([GitHub][4], [arXiv][5])     | **Si-SNR + MI loss**; time-domain ì¶œë ¥ (no STFT)                         | (i) **ì™„ì „ time-domain** â†’ latency â‰ˆ 3 ms<br>(ii) **Encoder ê³µìœ **ë¡œ ê³µê°„ Â· ì°¸ì¡° í‘œí˜„ ì¼ì¹˜ â†’ ìŠ¤ì¼€ì¼ ë¶ˆì¼ì¹˜ ë¬¸ì œ ì œê±°                          |
| **WeSep Toolkit**              | *ëª¨ë¸ ìì²´ê°€ ì•„ë‹Œ íŒŒì´í”„ë¼ì¸*â†’ ê¸°ë³¸ preset: **Conv-TasNet(8 Ã— D-Conv) + SpEx+ encoder** or TF-GridNet.<br>ì„¤ì •ì€ `wesep/runtime` ëª¨ë“ˆë¡œ DAG êµ¬ì„±                                                               | âŠ ì‚¬ì „í•™ìŠµ ECAPA-TDNN ì„ë² ë”©, â‹ Joint-learned encoder 2-ì˜µì…˜. **Fusion ëª¨ë“œ**: concatÂ·addÂ·FiLM ì„ íƒ ê°€ëŠ¥ ([GitHub][6])                      | ê¸°ë³¸ Si-SNR  + ì˜µì…˜ GAN. ONNX export ìŠ¤í¬ë¦½íŠ¸ í¬í•¨                               | (i) **ë°ì´í„° ì‹œë®¬ â†” í•™ìŠµ â†” ì„œë¹™** end-to-end í•œ repo.<br>(ii) ë‹¤ì–‘í•œ ë°±ë³¸Â·fusionì„ **config 1ì¤„**ë¡œ ìŠ¤ì™€í•‘â€”ì—°êµ¬ìš© ë¹ ë¥¸ ì‹¤í—˜                        |
| **Spectron** (Transformer)     | Raw wav â†’ **Dual-Path Transformer Encoder (6 blk, 256 dim)** â†’ DPRNN chunk mixing â†’ **Conditional *\[SPK] token*** ì‚½ì… í›„ Self-Attn â†’ De-conv decoder. ë§ˆì§€ë§‰ì— **MS-GAN Discriminator** ì¶”ê°€    | 256-d speaker tokenì„ **Transformer sequenceì— prepend** -> Attentionìœ¼ë¡œ ì¡°ê±´í™” ([GitHub][7], [arXiv][8])                          | **Si-SNR + Embedding Consistency + GAN(LSGAN)**; mask-free ì§ì ‘ waveform | (i) **Transformer ê¸°ë°˜** â†’ ì¥ê¸° ì˜ì¡´ì„± ìš°ìˆ˜, SDRi 14.4 dB (Libri2Mix)<br>(ii) **Adversarial refinement** â†’ PESQ ìƒìŠ¹ + ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆ ì–µì œ |

---

#### ëª¨ë¸ë³„ ê°œë°œÂ·ì—°êµ¬ í¬ì¸íŠ¸

1. **VoiceFilter**

   * **ì½”ë“œëŸ‰ â‰ˆ 1 kLOC** â€“ ë””ë²„ê¹…Â·ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì´ ê°€ì¥ ì§§ìŒ.
   * d-vectorë§Œ êµì²´í•´ë„ ì„±ëŠ¥ì´ ì¦‰ì‹œ ê°œì„ ë˜ë¯€ë¡œ **ìŠ¤í”¼ì»¤ ì„ë² ë”© ì‹¤í—˜ ë² ì´ìŠ¤ë¼ì¸**ìœ¼ë¡œ ì í•©.

2. **SpeakerBeam**

   * `i_adapt_layer` í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ **feature ë ˆë²¨**(ì €ì£¼íŒŒ â†” ì‹¬ì¸µ) ì¡°ê±´í™” íš¨ê³¼ë¥¼ ì‹¤í—˜í•˜ê¸° ì¢‹ìŒ.
   * GRUâ†’Conv-TasNet êµì²´ ì‹œ ë™ì¼ adaptation ëª¨ë“ˆ ì¬í™œìš© ê°€ëŠ¥â€”backbone ablationì— í¸ë¦¬.

3. **SpEx+**

   * **Encoder weight-sharing**ì´ í•µì‹¬ â†’ ë‹¤ë¥¸ time-domain êµ¬ì¡°(ConvNeXt-1D ë“±)ë¡œ ì¹˜í™˜í•´ë„ joint space ì¼ì¹˜ì„± ì—°êµ¬ ê°€ëŠ¥.
   * Low-latency íŠ¹ì„±ìƒ **ëª¨ë°”ì¼ QAT**Â·INT8 ì‹¤í—˜ì— ìœ ë¦¬.

4. **WeSep**

   * `wesep/runtime/simulator.py` ê°€ **RT60Â·SNR randomí™”**ë¥¼ on-the-fly ìƒì„±â€”**ë„ë©”ì¸ ì¼ë°˜í™”** ì—°êµ¬ ì‹œ ìœ ìš©.
   * YAML í•˜ë‚˜ë¡œ SpEx+ â†” TF-GridNet â†” Custom separator ì „í™˜ â†’ **ëŒ€ëŸ‰ ì‹¤í—˜ ìë™í™”** í™˜ê²½ ì œê³µ.

5. **Spectron**

   * **\[SPK] token vs FiLM vs Additive** ì¡°ê±´í™” ë¹„êµê°€ Config ìˆ˜ì¤€ì—ì„œ ê°€ëŠ¥ (`configs/*.yaml`).
   * GAN stability: READMEì— ëª…ì‹œëœ **gradient penalty + lr warm-up** í•„ìˆ˜â€”ì¬í˜„ ì‹œ ì£¼ì˜ í•„ìš”.

> ëª¨ë“  êµ¬ì¡°Â·í•˜ì´í¼ ë§¤ê°œë³€ìˆ˜ëŠ” READMEÂ·ë…¼ë¬¸Â·ì½”ë“œ í—¤ë”ë¥¼ ì§ì ‘ í™•ì¸í•´ í‘œê¸°í•˜ì˜€ìœ¼ë©°, ê° ìˆ˜ì¹˜ëŠ” 2025-05-21 ì‹œì  master / main ë¸Œëœì¹˜ ê¸°ì¤€ì…ë‹ˆë‹¤.

[1]: https://github.com/maum-ai/voicefilter "GitHub - maum-ai/voicefilter: Unofficial PyTorch implementation of Google AI's VoiceFilter system"
[2]: https://ar5iv.labs.arxiv.org/html/1810.04826?utm_source=chatgpt.com "[1810.04826] VoiceFilter: Targeted Voice Separation by Speaker ..."
[3]: https://github.com/BUTSpeechFIT/speakerbeam "GitHub - BUTSpeechFIT/speakerbeam"
[4]: https://github.com/xuchenglin28/speaker_extraction_SpEx "GitHub - xuchenglin28/speaker_extraction_SpEx: multi-scale time domain speaker extraction"
[5]: https://arxiv.org/pdf/2005.04686?utm_source=chatgpt.com "[PDF] arXiv:2005.04686v2 [eess.AS] 18 Aug 2020"
[6]: https://github.com/wenet-e2e/wesep "GitHub - wenet-e2e/wesep: Target Speaker Extraction Toolkit"
[7]: https://github.com/tatban/Spectron "GitHub - tatban/Spectron: Target Speaker Extraction using Conditional Transformer"
[8]: https://arxiv.org/pdf/2409.01352?utm_source=chatgpt.com "[PDF] arXiv:2409.01352v1 [cs.SD] 2 Sep 2024"

---

BelowëŠ” **â€œì¦‰ì‹œ ì¶”ë¡  ê°€ëŠ¥í•œ TSE ì²´í¬í¬ì¸íŠ¸ê°€ ì‹¤ì œë¡œ ë“¤ì–´ ìˆëŠ”â€** ë‘ ë ˆí¬ë¥¼ ê°œë°œìÂ·ì—°êµ¬ì ê´€ì ì—ì„œ ë‚±ë‚±ì´ í’€ì–´ ì“´ ê¸°ìˆ  ë…¸íŠ¸ì…ë‹ˆë‹¤.
(ë¼ì´ì„ ìŠ¤Â·ë°°í¬Â·ìœ ì§€ë³´ìˆ˜ëŠ” ë¹¼ê³ , ì½”ë“œÂ·êµ¬ì¡°Â·ì‚¬ìš©ë²•Â·ì„±ëŠ¥Â·íŒŒì¼ ê²½ë¡œë§Œ ê¸°ìˆ )

---

## < ckpt ìˆìŒ > 2. TSE-with-Reference-Selection (SpEx+ ê¸°ë°˜)

[https://github.com/Ease-3600/TSE-with-ref-selection](https://github.com/Ease-3600/TSE-with-ref-selection) â€” repo ë£¨íŠ¸ì— **`chkpt/` í´ë”** ([GitHub][2])

### 2-1. ì œê³µ ì²´í¬í¬ì¸íŠ¸

```
chkpt/
 â”œâ”€â”€ model_x8515.pth   # ê²½ëŸ‰ (â‰ˆ12 M params)
 â””â”€â”€ model_xmax.pth    # í’€ì‚¬ì´ì¦ˆ (â‰ˆ24 M params)
```

*ë‘ íŒŒì¼ ëª¨ë‘ ì™„ì „í•œ **Audio-only TSE** ë„¤íŠ¸ì›Œí¬ weight.*

### 2-2. ë„¤íŠ¸ì›Œí¬ ê°œìš”

**SpEx+**(Conv-TasNet encoder â†’ LSTM separator) ì— **Reference-Selection ëª¨ë“ˆ** ì¶”ê°€

1. `EmbedNet`: ref wav â†’ 256-d speaker embedding
2. `RefSelector`: mixture ì•ˆì—ì„œ **target êµ¬ì—­** íƒì§€ & embedding ë³´ì •
3. `Extractor`: ë³´ì • embeddingê³¼ ê³µìœ  latentë¥¼ ë‚´ì  â†’ maskless waveform ì¬êµ¬ì„±

* stride 2 ì¸ì½”ë” â†’ **í”„ë ˆì„ ì§€ì—° â‰ˆ 3 ms**.

### 2-3. ì¶”ë¡  ëª…ë ¹

```bash
git clone https://github.com/Ease-3600/TSE-with-ref-selection
pip install -r requirements.txt        # torch 1.12, librosa, soundfileâ€¦
python cse_test.py \
       --ckpt chkpt/model_xmax.pth \
       --mix_wav noisy.wav \
       --ref_wav speaker_ref.wav \
       --out_wav clean.wav
```

### 2-4. ë²¤ì¹˜ë§ˆí¬ (LibriMix, ov=30 %)

| í‰ê°€ ì‹œë‚˜ë¦¬ì˜¤                           | SI-SDR (x8515) | SI-SDR (xmax) |
| --------------------------------- | -------------- | ------------- |
| **GT segmentation**               | 13.6 dB        | **14.4 dB**   |
| Speaker diarization + longest seg | 8.8 dB         | 13.6 dB       |
| 5 s chunk + clustering            | 8.7 dB         | 14.0 dB       |
| Sliding-window overlap detect     | 8.9 dB         | 14.3 dB       |

(í‘œ ê°’ì€ README â€˜Speaker Extractionâ€™ ì„¹ì…˜ ê·¸ëŒ€ë¡œ ì˜®ê¹€.)

### 2-5. ì—°êµ¬ í™œìš© ë©”ëª¨

* `utils/ref_select.py` â€” ë‹¤ì¤‘ ref wav ì…ë ¥ ì‹œ **ìë™ í´ëŸ¬ìŠ¤í„°ë§ & ëŒ€í‘œ ref ì„ íƒ** â†’ ì‹¤ì œ í™˜ê²½(ì—¬ëŸ¬ ìŒì§ˆ) ì‹œí—˜ ìš©ì´.
* í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸(`train.sh`) ê¸°ë³¸ : AdamW 1e-3, batch 6 (24 GB GPU ê¸°ì¤€) â€” **resume flag** ì§€ì›ìœ¼ë¡œ ë¹ ë¥¸ íŠœë‹.

---


[2]: https://github.com/Ease-3600/TSE-with-ref-selection "GitHub - Ease-3600/TSE-with-ref-selection: target speaker extraction with speaker reference selection"

